# Badwords Filter Improvement Plan - Frontend Text Validation

**Date:** Nov 3, 2025  
**Issue:** False positives in Vietnamese badwords filter (e.g., "táº¡o" is blocked)  
**Status:** Planning & Implementation

---

## ğŸ” Problem Analysis

### Current Issues

1. **"táº¡o" (create) is blocked** 
   - Reason: Badwords list contains "tao" (meaning "I" in slang/colloquial Vietnamese)
   - Pattern: "tao" is matched as standalone word
   - False positive: "táº¡o" contains "tao" after Unicode normalization

2. **Other potential false positives:**
   - "táº¡o" â†’ matches "tao" (I/me in slang)
   - "mÃ y" (you in slang) could match legitimate words containing it
   - "bá»‘" (father in slang) could match legitimate uses
   - Short words are problematic with phrase-based matching

3. **Root Cause:**
   - Badwords list mixes legitimate Vietnamese words with slang
   - Unicode normalization removes diacritics: "táº¡o" â†’ "tao"
   - Word boundaries sometimes too permissive

---

## ğŸ“‹ Solution Strategy

### Strategy 1: Smart Whitelisting (QUICK FIX) â­ RECOMMENDED

**Pros:**
- Fast implementation
- Minimal changes
- Handles false positives case-by-case
- Easy to maintain list

**Cons:**
- Reactive (fixes reported issues)
- Limited scalability

**Implementation:**
```typescript
// vnBadwordsFilter.ts
const WHITELIST = new Set([
  "táº¡o",           // create (confuses with slang "tao")
  "táº¡o bÃ i",       // create quiz
  "bá»‘ máº¹",         // parents (legitimate family term)
  "con",           // child (legitimate family term)
  // Add more as needed
]);

// In containsVietnameseBadwords() function:
if (WHITELIST.has(normalizedText)) return false;
```

---

### Strategy 2: Context-Aware Filtering (MEDIUM-TERM)

**Separate badwords by context:**
- **Direct Insults:** "Ä‘á»“ ngu", "khá»‘n náº¡n" (always bad)
- **Slang Pronouns:** "tao", "mÃ y" (only bad in confrontational phrases)
- **Contextual:** "con" (can be innocent or offensive)

**Example:**
```typescript
const SLANG_PRONOUNS = new Set(["tao", "mÃ y", "gÃ¬"]);
const DIRECT_INSULTS = new Set(["Ä‘á»“ ngu", "khá»‘n náº¡n"]);

// Only flag if slang pronoun is in confrontational context
// e.g., "tao giáº¿t mÃ y" YES, but "táº¡o quiz" NO
```

---

### Strategy 3: Refactor Badwords List (LONG-TERM)

**Clean up `badwords_vi.json`:**

1. **Remove single-character/2-char words** that cause too many false positives:
   - "tao" â†’ Remove (confuses with "táº¡o")
   - "mÃ y" â†’ Remove (too common in legitimate text)
   - "gÃ¬" â†’ Remove (means "what" in Vietnamese)
   - Keep: Longer, clearly offensive phrases

2. **Add context metadata:**
```json
{
  "tuc_tieu": [
    {
      "word": "Ä‘á»‹t máº¹",
      "severity": "high",
      "context": "direct_insult"
    }
  ]
}
```

3. **Categorize by severity:**
   - HIGH: Never acceptable
   - MEDIUM: Contextual warning
   - LOW: Depends on context

---

## ğŸ› ï¸ Implementation Plan (This Session)

### Phase 1: Quick Fix (30 minutes) âœ… DO THIS NOW

1. **Add common false positives to whitelist**
2. **Test with user-reported examples**
3. **Deploy immediately**

### Phase 2: Collect Data (Ongoing)

1. **Track false positives** from users
2. **Log what words are being flagged**
3. **Build comprehensive whitelist**

### Phase 3: Refactor (Next Session)

1. **Reorganize badwords list**
2. **Add severity levels**
3. **Implement context-aware filtering**

---

## ğŸ“ Quick Fix Implementation

### Step 1: Update Whitelist in vnBadwordsFilter.ts

```typescript
// Around line 90-100
const WHITELIST = new Set([
  // False positive fixes (words that are legitimate but match badwords)
  "táº¡o",                    // create (confuses with slang "tao")
  "táº¡o bÃ i kiá»ƒm tra",       // create quiz
  "táº¡o bÃ i",                // create exercise
  "táº¡o quiz",               // create quiz (English context)
  "bá»‘ máº¹",                  // parents (family context)
  "con chÃ³",                // dog (animal context)
  "con mÃ¨o",                // cat (animal context)
  "con ngÆ°á»i",              // human/person
  
  // Add more as you discover them
]);

export function containsVietnameseBadwords(text: string): boolean {
  if (!text) return false;

  // Check whitelist first
  const normalizedForWhitelist = normalizeForCompare(text.trim());
  for (const w of WHITELIST) {
    if (normalizedForWhitelist === normalizeForCompare(w)) {
      return false; // Whitelisted, not a badword
    }
  }

  // Then check badwords... (existing logic)
  const normalized = normalizeForCompare(text);
  // ... rest of function
}
```

### Step 2: Add More Aggressive Word Boundary

Current implementation might allow partial matches. Options:

**Option A: Stricter boundaries**
```typescript
// Only match complete words, not parts of words
const BADWORDS_REGEX = new RegExp(
  patternsWithBoundaries.join("|"),
  "giu"
);
// Add: must be surrounded by word boundaries OR line boundaries
```

**Option B: Phrase-only matching**
```typescript
// Only flag if it's a multi-word phrase (harder to accidentally match)
const isPhrase = patterns.some(p => p.includes(separator));
if (!isPhrase) {
  // Single word - only flag if it's a known bad word on its own
  // not just part of another word
}
```

---

## ğŸ§ª Testing Strategy

### Test Cases

```javascript
// Test suite to validate
const testCases = [
  // Current false positives
  { input: "táº¡o", expected: false, reason: "legitimate word 'create'" },
  { input: "táº¡o bÃ i kiá»ƒm tra", expected: false, reason: "quiz creation context" },
  { input: "Táº¡o quiz cho há»c sinh", expected: false, reason: "normal use case" },
  
  // Should still catch real badwords
  { input: "Ä‘á»‹t máº¹", expected: true, reason: "direct insult" },
  { input: "Ä‘á»“ ngu", expected: true, reason: "insult" },
  { input: "vcl", expected: true, reason: "abbreviation" },
  
  // Edge cases
  { input: "táº¡o giáº¿t ngÆ°á»i", expected: true, reason: "contains threat" },
  { input: "Con chÃ³", expected: false, reason: "animal reference" },
  { input: "bá»‘ máº¹ em", expected: false, reason: "family context" },
];

// Run tests
testCases.forEach(test => {
  const result = containsVietnameseBadwords(test.input);
  const passed = result === test.expected;
  console.log(`${passed ? 'âœ…' : 'âŒ'} ${test.input}: ${test.reason}`);
});
```

---

## ğŸ“Š Comparison: Before vs After

| Scenario | Before | After | Fix Type |
|----------|--------|-------|----------|
| User enters "táº¡o" | âŒ Blocked | âœ… Allowed | Whitelist |
| "táº¡o bÃ i kiá»ƒm tra" | âŒ Blocked | âœ… Allowed | Whitelist |
| "Ä‘á»‹t máº¹" insult | âœ… Caught | âœ… Caught | No change |
| "con chÃ³" (dog) | âŒ Blocked | âœ… Allowed | Context |
| "bá»‘ máº¹" (parents) | âŒ Blocked | âœ… Allowed | Context |

---

## ğŸ”§ Files to Modify

### Phase 1 (This session)
1. **`src/lib/vnBadwordsFilter.ts`**
   - Add comprehensive whitelist
   - Improve word boundary logic
   - Add logging for debugging

### Phase 2 (Next session)
1. **`src/assets/filter/badwords_vi.json`**
   - Reorganize and cleanup
   - Remove problematic single words
   - Add severity metadata

### Phase 3 (Future)
1. **`src/components/ui/TextField.tsx`** (if exists)
   - Add real-time feedback
   - Show which word triggered filter
   - Provide suggestions

---

## ğŸ“Œ Decision Point

**Which approach do you want?**

**Option A: Quick Fix Now** (Recommended)
- Add whitelist for "táº¡o", "con", "bá»‘", etc.
- Deploy in 30 minutes
- âœ… Pros: Immediate relief, simple
- âŒ Cons: Not scalable long-term

**Option B: Refactor Now**
- Reorganize badwords_vi.json
- Implement severity levels
- Add context awareness
- â³ Pros: Better architecture
- âŒ Cons: Takes 2-3 hours

**Option C: Hybrid**
- Quick whitelist now (Phase 1)
- Plan refactor for next session (Phase 2)
- âœ… Best of both worlds

---

## ğŸš€ Quick Implementation Checklist

- [ ] Identify all false positives (you report them)
- [ ] Add to whitelist in vnBadwordsFilter.ts
- [ ] Run test cases
- [ ] Deploy to production
- [ ] Monitor for more false positives
- [ ] Build comprehensive list over time

**Next Question:** Should I start with the quick fix (whitelist approach)?

